---

title: Linear Regression

keywords: fastai
sidebar: home_sidebar

summary: "This tutorial describes linear regression technique and demonstrates how it works via an example of fitting a curve using linear regression."
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 03_linear_regression_old.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Regression">Regression<a class="anchor-link" href="#Regression">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Regression is an approach to modeling the relationship between a real-valued target $y$ (dependent variable) and data points $\mathbf{x}$ (independent variables). In other words, linear regression describes the relationship between input and output and predicts the output based on the input data.
{% include note.html content='<strong>x</strong> is a vector of features, i.e. $\mathbf{x} = &lt;x_1, x_2,\cdots, x_n&gt;$' %}
Examples of linear regression include, predicting the weight from gender, age, and height, or predicting the stock price today from the prices of yesterday.</p>
<p>We wish to learn $f:X\to Y$, where $Y$ is a real number, given $\{&lt;X^1,y^1&gt;,\cdots, &lt;X^m,y^m&gt;\}$.</p>
<p><strong>Approach</strong></p>
<p>1- Choose some parametraized form for $P(Y|X;\theta)$</p>
<p>2- Derive learning algorithms as Maximum Likelihood Estimates (MLE), or Maximum a Posteriori (MAP) estimate for $\theta$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Linear-Regression-Model">Linear Regression Model<a class="anchor-link" href="#Linear-Regression-Model">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's assume that we are going to predict the price of houses (in dollars), $y$, based on their area (in square feet), $x$. Therefore, training set = $\{&lt;x^1,y^1&gt;,\cdots,&lt;x^m,y^m&gt;\}$, where:</p>
<ul>
<li><p>$m$: number of trainig examples</p>
</li>
<li><p>$x$: input variable</p>
</li>
<li><p>$y$: output variable or target label</p>
</li>
<li><p>$(x^i,y^i)$: is the $i$th training example</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html height="500" max-width="500" file="/ml_tutorial/images/linear_regression_ex.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We may think of a line as the regression model to predict the prices of houses from their area.</p>
<p>{% include image.html height="500" max-width="500" file="/ml_tutorial/images/lr_house_line_ex.png" %}</p>
<p>Someone might consider a quadratic function or even high order polynomial functions to do the prediction.</p>
<p>{% include image.html height="500" max-width="500" file="/ml_tutorial/images/lr_house_ex.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Polynomial-Regression-Model">Polynomial Regression Model<a class="anchor-link" href="#Polynomial-Regression-Model">&#182;</a></h2><p>If we represent the relationship between the independent variable $x$ and dependent variable $y$ as an $n$th degree polynomial, then the regression model is called <strong>polynomial regression</strong>. Therefore, we have:</p>
$$y_i=w_0+w_1x_i+w_2x_i^2+\cdots+w_nx_i^n+\epsilon_i$$<p>We treat each $x_i^p$ for $p=1,\cdots,n$ as a different feature. i.e. $feature\ 1=x, feature\ 2=x^2,\cdots, feature\ n=x^n$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="General-Expansion">General Expansion<a class="anchor-link" href="#General-Expansion">&#182;</a></h2><p>In general, if we have a dataset of $m$ instances with $k$ features, $\mathbf{x}=&lt;x_1,x_2,\cdots,x_k&gt;$ and a real valued target $y$, then the linear regression model takes the form:</p>
$$y_i=w_0+w_1h_1(x_1)+w_2h_2(x_2)+\cdots+w_kh_k(x_k)+\epsilon_i= w_0 +\sum_{j=1}^{k}w_jh_j(x_i)+\epsilon_i$$<p>Considering our house price prediction, instead of using only area of the house, we can add more features such as number of bathrooms, number of bedrooms, age of the house, etc.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Regression-Problem">The Regression Problem<a class="anchor-link" href="#The-Regression-Problem">&#182;</a></h2><p>The general approach is as follows:</p>
<ul>
<li><p>Instances: $&lt;\mathbf{x}_i,y_i&gt;$</p>
</li>
<li><p>Learn: mapping from $\mathbf{x}$ to $y\equiv f(\mathbf{x})$</p>
</li>
<li><p>Given the basis functions $h_1, h_2,\cdots,h_k$ where $h_j(\mathbf{x})\in \mathbb{R}$</p>
</li>
<li><p>Find coeffcients $\mathbf{x}=[w_0,w_1,\cdots,w_k]$, where $f(\mathbf{x})\thickapprox \hat{f}(\mathbf{x})=w_0+\sum_{j}w_jh_j(\mathbf{x})$</p>
</li>
<li><p>In order to find coefficients, we need to minimize the <strong>mean residual square error</strong>:</p>
</li>
</ul>
$$J(\mathbf{w}) = \frac{1}{m}\sum_{i=1}^{m}\left( f(\mathbf{x}_i) - \left(w_0 +\sum_{j=1}^{k}w_jh_j(\mathbf{x})\right)\right)^2$$$$\mathbf{w}^* = \underset{\mathbf{w}}{\arg\min}\ J(\mathbf{w})$$<p>{% include note.html content='The reason it&#8217;s called <em>linear</em> regression is that the model is a linear combinations of the input features.' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Example:-Fit-a-Line-to-Two-Diminsional-Data">Example: Fit a Line to Two Diminsional Data<a class="anchor-link" href="#Example:-Fit-a-Line-to-Two-Diminsional-Data">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We would like to find a <strong>line</strong> that <strong>fits</strong> our training examples the <strong>best</strong>.</p>
<p>{% include image.html height="500" max-width="500" file="/ml_tutorial/images/linear_regression_ex_model.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since we are looling for a line to fit our training set, we need to find a function $\hat y = f(x)$ that estimates $y^i$ for all $1\leq i \leq m$. Thus, we have:</p>
<p>$\hat y = f(x) = w_0 + w_1x$</p>
<p>$w_0$ and $w_1$ are the paramaters that we need to find.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Cost-Function-(Error-Function)">Cost Function (Error Function)<a class="anchor-link" href="#Cost-Function-(Error-Function)">&#182;</a></h2><p>We wish to estimate the actual $y$, i.e. we want to minimize the error as much as possible. The error is the difference between the actual $y^i$ and our estimated/predicted $\hat{y}^i$ for all $1\leq i \leq m$.</p>
<p>The error/cost function is:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$J(w_0,w_1) = \frac{1}{m}\sum_{i=1}^{m}\left( y^i - (w_0 + w_1 x^i)\right)^2$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Precisely, we need to minimize the <strong>mean residual squared error</strong>:</p>
$$\text{minimize } J(w_0,w_1) = \underset{\mathbf{w0,w_1}}{\arg\min} \frac{1}{m}\sum_{i=1}^{m}\left( \hat{y}^i - (w_0 + w_1 x^i)\right)^2$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Fitting-the-Linear-Regression-Model-using-Gradient-Descent-Algorithm">Fitting the Linear Regression Model using Gradient Descent Algorithm<a class="anchor-link" href="#Fitting-the-Linear-Regression-Model-using-Gradient-Descent-Algorithm">&#182;</a></h2><p>In order to mininze the cost function, we need to take the gradient (i.e. derivative) of the function with resptect to our parameters $w_0$ and $w_1$, set it zero and solve for $w_0$ and $w_1$.</p>
$$\frac{\partial{J}}{\partial{w_0}} = \frac{-2}{m} \sum_{i=1}^{m}\left(\hat{y}^i - (w_0 + w_1 x^i)\right)$$$$\frac{\partial{J}}{\partial{w_1}} = \frac{-2}{m} \sum_{i=1}^{m}x^i\left(\hat{y}^i - (w_0 + w_1 x^i)\right)$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-gradient-descent-algorithm:">The gradient descent algorithm:<a class="anchor-link" href="#The-gradient-descent-algorithm:">&#182;</a></h2><p>initialize $w_0^{(0)} = w_1^{(0)} = 0$, for $t=0$</p>
<p>for $t=1$ to <em>num_iterations</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
$w_0^{(t+1)} = w_0^{(t)} - \eta \frac{-2}{m} \sum_{i=1}^{m}\left(\hat{y}^i - (w_0 + w_1 x^i)\right) $</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
$w_1^{(t+1)} = w_1^{(t)} - \eta\frac{-2}{m} \sum_{i=1}^{m}x^i\left(\hat{y}^i - (w_0 + w_1 x^i)\right)$</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$t = t+1$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implemented-Functions">Implemented Functions<a class="anchor-link" href="#Implemented-Functions">&#182;</a></h2><p>All the functions, their implementations and documentations are described below.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="generate_data" class="doc_header"><code>generate_data</code><a href="https://github.com/sci2lab/ml_tutorial/tree/master/ml_tutorial/linear_regression.py#L9" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>generate_data</code>()</p>
</blockquote>
<p>It generates dummy data.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="make_point_plot" class="doc_header"><code>make_point_plot</code><a href="https://github.com/sci2lab/ml_tutorial/tree/master/ml_tutorial/linear_regression.py#L17" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>make_point_plot</code>(<strong><code>x</code></strong>, <strong><code>y</code></strong>)</p>
</blockquote>
<p>It plots the point chart of the data</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="make_line_plot" class="doc_header"><code>make_line_plot</code><a href="https://github.com/sci2lab/ml_tutorial/tree/master/ml_tutorial/linear_regression.py#L29" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>make_line_plot</code>(<strong><code>x</code></strong>, <strong><code>y</code></strong>)</p>
</blockquote>
<p>It plots the line chart of the data</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gradient_descent" class="doc_header"><code>gradient_descent</code><a href="https://github.com/sci2lab/ml_tutorial/tree/master/ml_tutorial/linear_regression.py#L40" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>gradient_descent</code>(<strong><code>data</code></strong>, <strong><code>w_0_t</code></strong>, <strong><code>w_1_t</code></strong>, <strong><code>learning_rate</code></strong>, <strong><code>num_iterations</code></strong>)</p>
</blockquote>
<p>Gradient descent implementation, which gets <code>data</code>, starting <code>w_0</code> and <code>w_1</code>, <code>learning_rate</code>
and the number of iterations <code>num_iterations</code></p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Run-an-Example">Run an Example<a class="anchor-link" href="#Run-an-Example">&#182;</a></h2><p>In this example, we generate some linear-looking data and then find the line that fits the data. The function that we use to generate the data is $y=5+3x+\text{Gaussian noise}$. Our goal is to find $\theta=[w_0,w_1]$ where $w_0=5$ and $w_1=3$ or close enough, as we have noise and it makes it impossible to recover the exact paratmeters of the function. We use the <a href="/ml_tutorial/linear_regression_old#generate_data"><code>generate_data</code></a> function to generate the training data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The chart below shows the generated dataset.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">origin_chart</span> <span class="o">=</span> <span class="n">make_point_plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

<span class="c1">#show the chart</span>
<span class="n">origin_chart</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">

<div id="altair-viz-10d189d62b484e38824bfe5532d11803"></div>
<script type="text/javascript">
  (function(spec, embedOpt){
    const outputDiv = document.getElementById("altair-viz-10d189d62b484e38824bfe5532d11803");
    const paths = {
      "vega": "https://cdn.jsdelivr.net/npm//vega@5?noext",
      "vega-lib": "https://cdn.jsdelivr.net/npm//vega-lib?noext",
      "vega-lite": "https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext",
      "vega-embed": "https://cdn.jsdelivr.net/npm//vega-embed@6?noext",
    };

    function loadScript(lib) {
      return new Promise(function(resolve, reject) {
        var s = document.createElement('script');
        s.src = paths[lib];
        s.async = true;
        s.onload = () => resolve(paths[lib]);
        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);
        document.getElementsByTagName("head")[0].appendChild(s);
      });
    }

    function showError(err) {
      outputDiv.innerHTML = `<div class="error" style="color:red;">${err}</div>`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === "function" && define.amd) {
      requirejs.config({paths});
      require(["vega-embed"], displayChart, err => showError(`Error loading script: ${err.message}`));
    } else if (typeof vegaEmbed === "function") {
      displayChart(vegaEmbed);
    } else {
      loadScript("vega")
        .then(() => loadScript("vega-lite"))
        .then(() => loadScript("vega-embed"))
        .catch(showError)
        .then(() => displayChart(vegaEmbed));
    }
  })({"config": {"view": {"continuousWidth": 400, "continuousHeight": 300}}, "data": {"name": "data-2c13ca96d8ed3d58170a6781550c735d"}, "mark": {"type": "point", "color": "red", "filled": true, "size": 50}, "encoding": {"x": {"type": "quantitative", "field": "x"}, "y": {"type": "quantitative", "field": "y"}}, "$schema": "https://vega.github.io/schema/vega-lite/v4.0.2.json", "datasets": {"data-2c13ca96d8ed3d58170a6781550c735d": [{"x": 0.9650530322982529, "y": 6.885075795845718}, {"x": 1.1482871707117908, "y": 10.124399480561408}, {"x": 1.969060666502852, "y": 11.820097463094713}, {"x": 1.6605812273822977, "y": 9.689834905979527}, {"x": 0.8270880909652947, "y": 8.209589780080504}, {"x": 1.2004532749885235, "y": 6.329320744298237}, {"x": 1.51037868404456, "y": 8.376263803462578}, {"x": 1.339532228659762, "y": 8.704696773908099}, {"x": 0.014441001445058665, "y": 4.135087657815116}, {"x": 0.4011088662828377, "y": 5.436922419749539}, {"x": 0.8449873357619617, "y": 6.654399184425406}, {"x": 1.6589799406930354, "y": 11.93341943993752}, {"x": 1.0228893674100294, "y": 8.639537867518376}, {"x": 0.43226789253278985, "y": 6.0651243013344525}, {"x": 1.5335785250746041, "y": 9.122549992895383}, {"x": 1.5420362322010785, "y": 10.091959617652437}, {"x": 1.8768441269628304, "y": 10.050846694541482}, {"x": 0.5558670551039695, "y": 5.9136721630799425}, {"x": 1.439694990929656, "y": 9.250975640954543}, {"x": 0.4552990384719411, "y": 5.557353353984224}, {"x": 1.3713534627634056, "y": 8.886760627155535}, {"x": 0.9999979788906448, "y": 7.336980538702023}, {"x": 1.9279579291237228, "y": 10.46436293672319}, {"x": 0.7347565869339214, "y": 6.994454280379741}, {"x": 1.0174549847403866, "y": 6.6970657008093015}, {"x": 0.682763651993513, "y": 8.124657031425025}, {"x": 1.6967193962776341, "y": 10.138707642077486}, {"x": 0.7076018921068004, "y": 7.2445136965277666}, {"x": 1.8050844282505767, "y": 10.620723943144776}, {"x": 0.7175425931388386, "y": 6.184968273881292}, {"x": 0.9019972904860623, "y": 8.100715850062748}, {"x": 0.09732217462876713, "y": 4.588842316824304}, {"x": 0.44212330242245157, "y": 3.718796699263354}, {"x": 1.3525755937154273, "y": 9.74243812505518}, {"x": 1.8559948859005087, "y": 12.132574152222519}, {"x": 1.1874856038639985, "y": 8.54454581240605}, {"x": 1.7096252475415272, "y": 10.035237175652366}, {"x": 1.0467243162840525, "y": 6.9674194899036115}, {"x": 0.734074972771263, "y": 8.684140078365727}, {"x": 1.3419731712078284, "y": 7.681324708147374}, {"x": 0.422721690480919, "y": 6.6139915688214765}, {"x": 0.3003620714087609, "y": 5.505150537792485}, {"x": 1.9478730313482047, "y": 9.76497350591537}, {"x": 1.1215970909340052, "y": 7.35185338598803}, {"x": 0.665837454853808, "y": 7.600792102308763}, {"x": 1.385449905416822, "y": 8.285106800537037}, {"x": 1.321598846114617, "y": 9.615858105308503}, {"x": 1.4438765952648385, "y": 9.898109973419535}, {"x": 0.2706182969960875, "y": 5.692733326278992}, {"x": 1.3112176256112775, "y": 9.756741094709039}, {"x": 1.4395610684664937, "y": 10.488690723868858}, {"x": 1.9570265094191692, "y": 10.565571935194617}, {"x": 0.26841910589671336, "y": 4.211944550478203}, {"x": 1.5178133784585541, "y": 8.963732289832999}, {"x": 0.9831964333549164, "y": 6.970894643344087}, {"x": 0.7378408414293272, "y": 7.1251818595169505}, {"x": 0.3764439196868412, "y": 6.186112858065716}, {"x": 1.609846603755966, "y": 9.953825234708262}, {"x": 0.19266828936500668, "y": 5.725748562277591}, {"x": 1.782264032050294, "y": 10.14225275975572}, {"x": 0.846162595891603, "y": 8.447642050276075}, {"x": 0.8754196795814169, "y": 5.782936968024793}, {"x": 1.2015323638920146, "y": 7.945389751697121}, {"x": 0.7391863373612928, "y": 7.799354498796093}, {"x": 1.2609090644504675, "y": 8.478094179427806}, {"x": 0.9899616515726222, "y": 7.403022564986407}, {"x": 0.8614613680955354, "y": 7.432598351289746}, {"x": 0.9393844312059232, "y": 7.193692127108459}, {"x": 0.5897031084448316, "y": 7.431583757245379}, {"x": 0.5217510089977473, "y": 6.826634593793892}, {"x": 0.25142264794583524, "y": 5.136068780663402}, {"x": 0.7500855160458832, "y": 8.842030808467326}, {"x": 1.0673147082956242, "y": 8.091872973417404}, {"x": 1.1910543740056632, "y": 8.887698885428678}, {"x": 1.4783525898914582, "y": 9.574034671437571}, {"x": 1.9733059810921412, "y": 12.483492622970523}, {"x": 0.21926388771021088, "y": 7.020103326358218}, {"x": 0.7071045776232301, "y": 6.387523029346408}, {"x": 0.9772506182841878, "y": 6.8612095764124055}, {"x": 1.0885577375417403, "y": 10.084481692356603}, {"x": 0.6838082380206969, "y": 6.8280718436351675}, {"x": 1.0823245584885757, "y": 8.005751607162784}, {"x": 1.7087425984072393, "y": 11.124282115017115}, {"x": 0.8409281172801493, "y": 8.481875588782485}, {"x": 1.4162953363222714, "y": 10.980520609460163}, {"x": 0.8457656060503209, "y": 7.867600397255508}, {"x": 1.1629256072195078, "y": 10.48154421460431}, {"x": 1.650929661737914, "y": 7.914957856433146}, {"x": 1.2601153149613344, "y": 8.000505870722}, {"x": 1.1705498244883932, "y": 6.9032232582775235}, {"x": 1.2963213501638993, "y": 8.226756688154019}, {"x": 0.7174304941346203, "y": 8.354728977907875}, {"x": 0.5156769049289194, "y": 5.625028444445765}, {"x": 0.3475769349077156, "y": 6.025216350011274}, {"x": 0.14613332890684672, "y": 7.407261371864469}, {"x": 0.8452637147802509, "y": 5.757027529545203}, {"x": 1.595776876255243, "y": 10.299373632658558}, {"x": 1.82347707012953, "y": 9.739196597325702}, {"x": 1.409272492479724, "y": 6.634354061924385}, {"x": 0.9322760683137878, "y": 6.944553755344748}]}}, {"mode": "vega-lite"});
</script>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We set the initial parameters to 0:  $w_0^{(0)} = w_1^{(0)} = 0$, define the number of iterations of the graditent descent algorithm as well as the learning rate. Then, we run the <a href="/ml_tutorial/linear_regression_old#gradient_descent"><code>gradient_descent</code></a> function. The outputs of this function are the estimated parameters $w_0$ and $w_1$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">initial_w_0</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">initial_w_1</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="c1"># X,y = generate_data()</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">w_0</span><span class="p">,</span><span class="n">w_1</span> <span class="o">=</span> <span class="n">gradient_descent</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">initial_w_0</span><span class="p">,</span><span class="n">initial_w_1</span><span class="p">,</span><span class="n">learning_rate</span><span class="p">,</span><span class="n">num_iterations</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;w_0 = </span><span class="si">{}</span><span class="s2">, w_1 = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">w_0</span><span class="p">,</span><span class="n">w_1</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>w_0 = [4.60926576], w_1 = [3.24869531]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The estimated parameters are $w_0 = 4.966$ and $w_1 = 3.001$ that are close enough to $w_0=5$ and $w_1=3$. Let's plot the line.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_predicted</span> <span class="o">=</span> <span class="n">w_0</span> <span class="o">+</span> <span class="n">w_1</span> <span class="o">*</span> <span class="n">X</span>
<span class="n">line</span> <span class="o">=</span> <span class="n">make_line_plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y_predicted</span><span class="p">)</span>

<span class="c1">#show the charts</span>
<span class="n">origin_chart</span> <span class="o">+</span> <span class="n">line</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">

<div id="altair-viz-88c3649fe4284f3ca036fc7acb760acc"></div>
<script type="text/javascript">
  (function(spec, embedOpt){
    const outputDiv = document.getElementById("altair-viz-88c3649fe4284f3ca036fc7acb760acc");
    const paths = {
      "vega": "https://cdn.jsdelivr.net/npm//vega@5?noext",
      "vega-lib": "https://cdn.jsdelivr.net/npm//vega-lib?noext",
      "vega-lite": "https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext",
      "vega-embed": "https://cdn.jsdelivr.net/npm//vega-embed@6?noext",
    };

    function loadScript(lib) {
      return new Promise(function(resolve, reject) {
        var s = document.createElement('script');
        s.src = paths[lib];
        s.async = true;
        s.onload = () => resolve(paths[lib]);
        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);
        document.getElementsByTagName("head")[0].appendChild(s);
      });
    }

    function showError(err) {
      outputDiv.innerHTML = `<div class="error" style="color:red;">${err}</div>`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === "function" && define.amd) {
      requirejs.config({paths});
      require(["vega-embed"], displayChart, err => showError(`Error loading script: ${err.message}`));
    } else if (typeof vegaEmbed === "function") {
      displayChart(vegaEmbed);
    } else {
      loadScript("vega")
        .then(() => loadScript("vega-lite"))
        .then(() => loadScript("vega-embed"))
        .catch(showError)
        .then(() => displayChart(vegaEmbed));
    }
  })({"config": {"view": {"continuousWidth": 400, "continuousHeight": 300}}, "layer": [{"data": {"name": "data-2c13ca96d8ed3d58170a6781550c735d"}, "mark": {"type": "point", "color": "red", "filled": true, "size": 50}, "encoding": {"x": {"type": "quantitative", "field": "x"}, "y": {"type": "quantitative", "field": "y"}}}, {"data": {"name": "data-5628ab888c3a2dd7b87fa3873a975be6"}, "mark": {"type": "line", "size": 3}, "encoding": {"x": {"type": "quantitative", "field": "x"}, "y": {"type": "quantitative", "field": "y"}}}], "$schema": "https://vega.github.io/schema/vega-lite/v4.0.2.json", "datasets": {"data-2c13ca96d8ed3d58170a6781550c735d": [{"x": 0.9650530322982529, "y": 6.885075795845718}, {"x": 1.1482871707117908, "y": 10.124399480561408}, {"x": 1.969060666502852, "y": 11.820097463094713}, {"x": 1.6605812273822977, "y": 9.689834905979527}, {"x": 0.8270880909652947, "y": 8.209589780080504}, {"x": 1.2004532749885235, "y": 6.329320744298237}, {"x": 1.51037868404456, "y": 8.376263803462578}, {"x": 1.339532228659762, "y": 8.704696773908099}, {"x": 0.014441001445058665, "y": 4.135087657815116}, {"x": 0.4011088662828377, "y": 5.436922419749539}, {"x": 0.8449873357619617, "y": 6.654399184425406}, {"x": 1.6589799406930354, "y": 11.93341943993752}, {"x": 1.0228893674100294, "y": 8.639537867518376}, {"x": 0.43226789253278985, "y": 6.0651243013344525}, {"x": 1.5335785250746041, "y": 9.122549992895383}, {"x": 1.5420362322010785, "y": 10.091959617652437}, {"x": 1.8768441269628304, "y": 10.050846694541482}, {"x": 0.5558670551039695, "y": 5.9136721630799425}, {"x": 1.439694990929656, "y": 9.250975640954543}, {"x": 0.4552990384719411, "y": 5.557353353984224}, {"x": 1.3713534627634056, "y": 8.886760627155535}, {"x": 0.9999979788906448, "y": 7.336980538702023}, {"x": 1.9279579291237228, "y": 10.46436293672319}, {"x": 0.7347565869339214, "y": 6.994454280379741}, {"x": 1.0174549847403866, "y": 6.6970657008093015}, {"x": 0.682763651993513, "y": 8.124657031425025}, {"x": 1.6967193962776341, "y": 10.138707642077486}, {"x": 0.7076018921068004, "y": 7.2445136965277666}, {"x": 1.8050844282505767, "y": 10.620723943144776}, {"x": 0.7175425931388386, "y": 6.184968273881292}, {"x": 0.9019972904860623, "y": 8.100715850062748}, {"x": 0.09732217462876713, "y": 4.588842316824304}, {"x": 0.44212330242245157, "y": 3.718796699263354}, {"x": 1.3525755937154273, "y": 9.74243812505518}, {"x": 1.8559948859005087, "y": 12.132574152222519}, {"x": 1.1874856038639985, "y": 8.54454581240605}, {"x": 1.7096252475415272, "y": 10.035237175652366}, {"x": 1.0467243162840525, "y": 6.9674194899036115}, {"x": 0.734074972771263, "y": 8.684140078365727}, {"x": 1.3419731712078284, "y": 7.681324708147374}, {"x": 0.422721690480919, "y": 6.6139915688214765}, {"x": 0.3003620714087609, "y": 5.505150537792485}, {"x": 1.9478730313482047, "y": 9.76497350591537}, {"x": 1.1215970909340052, "y": 7.35185338598803}, {"x": 0.665837454853808, "y": 7.600792102308763}, {"x": 1.385449905416822, "y": 8.285106800537037}, {"x": 1.321598846114617, "y": 9.615858105308503}, {"x": 1.4438765952648385, "y": 9.898109973419535}, {"x": 0.2706182969960875, "y": 5.692733326278992}, {"x": 1.3112176256112775, "y": 9.756741094709039}, {"x": 1.4395610684664937, "y": 10.488690723868858}, {"x": 1.9570265094191692, "y": 10.565571935194617}, {"x": 0.26841910589671336, "y": 4.211944550478203}, {"x": 1.5178133784585541, "y": 8.963732289832999}, {"x": 0.9831964333549164, "y": 6.970894643344087}, {"x": 0.7378408414293272, "y": 7.1251818595169505}, {"x": 0.3764439196868412, "y": 6.186112858065716}, {"x": 1.609846603755966, "y": 9.953825234708262}, {"x": 0.19266828936500668, "y": 5.725748562277591}, {"x": 1.782264032050294, "y": 10.14225275975572}, {"x": 0.846162595891603, "y": 8.447642050276075}, {"x": 0.8754196795814169, "y": 5.782936968024793}, {"x": 1.2015323638920146, "y": 7.945389751697121}, {"x": 0.7391863373612928, "y": 7.799354498796093}, {"x": 1.2609090644504675, "y": 8.478094179427806}, {"x": 0.9899616515726222, "y": 7.403022564986407}, {"x": 0.8614613680955354, "y": 7.432598351289746}, {"x": 0.9393844312059232, "y": 7.193692127108459}, {"x": 0.5897031084448316, "y": 7.431583757245379}, {"x": 0.5217510089977473, "y": 6.826634593793892}, {"x": 0.25142264794583524, "y": 5.136068780663402}, {"x": 0.7500855160458832, "y": 8.842030808467326}, {"x": 1.0673147082956242, "y": 8.091872973417404}, {"x": 1.1910543740056632, "y": 8.887698885428678}, {"x": 1.4783525898914582, "y": 9.574034671437571}, {"x": 1.9733059810921412, "y": 12.483492622970523}, {"x": 0.21926388771021088, "y": 7.020103326358218}, {"x": 0.7071045776232301, "y": 6.387523029346408}, {"x": 0.9772506182841878, "y": 6.8612095764124055}, {"x": 1.0885577375417403, "y": 10.084481692356603}, {"x": 0.6838082380206969, "y": 6.8280718436351675}, {"x": 1.0823245584885757, "y": 8.005751607162784}, {"x": 1.7087425984072393, "y": 11.124282115017115}, {"x": 0.8409281172801493, "y": 8.481875588782485}, {"x": 1.4162953363222714, "y": 10.980520609460163}, {"x": 0.8457656060503209, "y": 7.867600397255508}, {"x": 1.1629256072195078, "y": 10.48154421460431}, {"x": 1.650929661737914, "y": 7.914957856433146}, {"x": 1.2601153149613344, "y": 8.000505870722}, {"x": 1.1705498244883932, "y": 6.9032232582775235}, {"x": 1.2963213501638993, "y": 8.226756688154019}, {"x": 0.7174304941346203, "y": 8.354728977907875}, {"x": 0.5156769049289194, "y": 5.625028444445765}, {"x": 0.3475769349077156, "y": 6.025216350011274}, {"x": 0.14613332890684672, "y": 7.407261371864469}, {"x": 0.8452637147802509, "y": 5.757027529545203}, {"x": 1.595776876255243, "y": 10.299373632658558}, {"x": 1.82347707012953, "y": 9.739196597325702}, {"x": 1.409272492479724, "y": 6.634354061924385}, {"x": 0.9322760683137878, "y": 6.944553755344748}], "data-5628ab888c3a2dd7b87fa3873a975be6": [{"x": 0.9650530322982529, "y": 7.744429029248694}, {"x": 1.1482871707117908, "y": 8.339700916257476}, {"x": 1.969060666502852, "y": 11.00614392669511}, {"x": 1.6605812273822977, "y": 10.003988218055959}, {"x": 0.8270880909652947, "y": 7.296222970708577}, {"x": 1.2004532749885235, "y": 8.509172694822148}, {"x": 1.51037868404456, "y": 9.516025919216304}, {"x": 1.339532228659762, "y": 8.960997840026469}, {"x": 0.014441001445058665, "y": 4.656180178250613}, {"x": 0.4011088662828377, "y": 5.912346259203112}, {"x": 0.8449873357619617, "y": 7.354372163421221}, {"x": 1.6589799406930354, "y": 9.99878612549061}, {"x": 1.0228893674100294, "y": 7.932321660162039}, {"x": 0.43226789253278985, "y": 6.013572441800725}, {"x": 1.5335785250746041, "y": 9.59139513407893}, {"x": 1.5420362322010785, "y": 9.618871647596196}, {"x": 1.8768441269628304, "y": 10.70656048672761}, {"x": 0.5558670551039695, "y": 6.4151084621813865}, {"x": 1.439694990929656, "y": 9.286396136548305}, {"x": 0.4552990384719411, "y": 6.088393617711907}, {"x": 1.3713534627634056, "y": 9.064375334175914}, {"x": 0.9999979788906448, "y": 7.857954513525685}, {"x": 1.9279579291237228, "y": 10.872613656338606}, {"x": 0.7347565869339214, "y": 6.996266046136634}, {"x": 1.0174549847403866, "y": 7.914667006643352}, {"x": 0.682763651993513, "y": 6.827356841983578}, {"x": 1.6967193962776341, "y": 10.12139011803826}, {"x": 0.7076018921068004, "y": 6.908048716272006}, {"x": 1.8050844282505767, "y": 10.473435089716606}, {"x": 0.7175425931388386, "y": 6.940343025142424}, {"x": 0.9019972904860623, "y": 7.53958013624073}, {"x": 0.09732217462876713, "y": 4.92543585727272}, {"x": 0.44212330242245157, "y": 6.045589665736494}, {"x": 1.3525755937154273, "y": 9.003371758974406}, {"x": 1.8559948859005087, "y": 10.63882765496752}, {"x": 1.1874856038639985, "y": 8.46704468239368}, {"x": 1.7096252475415272, "y": 10.16331729657512}, {"x": 1.0467243162840525, "y": 8.009754146901907}, {"x": 0.734074972771263, "y": 6.994051689399781}, {"x": 1.3419731712078284, "y": 8.968927718646512}, {"x": 0.422721690480919, "y": 5.982559739918942}, {"x": 0.3003620714087609, "y": 5.585050618696268}, {"x": 1.9478730313482047, "y": 10.937311755632663}, {"x": 1.1215970909340052, "y": 8.252992979126894}, {"x": 0.665837454853808, "y": 6.7723687846353595}, {"x": 1.385449905416822, "y": 9.110170381381977}, {"x": 1.321598846114617, "y": 8.902737744170281}, {"x": 1.4438765952648385, "y": 9.29998089496112}, {"x": 0.2706182969960875, "y": 5.488422158111941}, {"x": 1.3112176256112775, "y": 8.869012321757289}, {"x": 1.4395610684664937, "y": 9.28596106326966}, {"x": 1.9570265094191692, "y": 10.967048616957594}, {"x": 0.26841910589671336, "y": 5.481277656290655}, {"x": 1.5178133784585541, "y": 9.540178976127368}, {"x": 0.9831964333549164, "y": 7.803371411259311}, {"x": 0.7378408414293272, "y": 7.006285849266071}, {"x": 0.3764439196868412, "y": 5.832217362752422}, {"x": 1.609846603755966, "y": 9.839166883973732}, {"x": 0.19266828936500668, "y": 5.2351863335180555}, {"x": 1.782264032050294, "y": 10.399298575494722}, {"x": 0.846162595891603, "y": 7.358190225498272}, {"x": 0.8754196795814169, "y": 7.4532375762114}, {"x": 1.2015323638920146, "y": 8.512678325887368}, {"x": 0.7391863373612928, "y": 7.010656955596574}, {"x": 1.2609090644504675, "y": 8.70557513481069}, {"x": 0.9899616515726222, "y": 7.825349543988002}, {"x": 0.8614613680955354, "y": 7.407891275082161}, {"x": 0.9393844312059232, "y": 7.661039565137907}, {"x": 0.5897031084448316, "y": 6.525031490147319}, {"x": 0.5217510089977473, "y": 6.304275823030401}, {"x": 0.25142264794583524, "y": 5.426061342974353}, {"x": 0.7500855160458832, "y": 7.046065066326353}, {"x": 1.0673147082956242, "y": 8.076646056963538}, {"x": 1.1910543740056632, "y": 8.478638529233152}, {"x": 1.4783525898914582, "y": 9.411982897183957}, {"x": 1.9733059810921412, "y": 11.019935660311956}, {"x": 0.21926388771021088, "y": 5.321587329261257}, {"x": 0.7071045776232301, "y": 6.906433093039159}, {"x": 0.9772506182841878, "y": 7.784055269695289}, {"x": 1.0885577375417403, "y": 8.145658186551417}, {"x": 0.6838082380206969, "y": 6.830750383716185}, {"x": 1.0823245584885757, "y": 8.125408486963957}, {"x": 1.7087425984072393, "y": 10.160449838467786}, {"x": 0.8409281172801493, "y": 7.341184999356869}, {"x": 1.4162953363222714, "y": 9.210377788253105}, {"x": 0.8457656060503209, "y": 7.356900526460803}, {"x": 1.1629256072195078, "y": 8.387256736358754}, {"x": 1.650929661737914, "y": 9.97263322196481}, {"x": 1.2601153149613344, "y": 8.702996484564075}, {"x": 1.1705498244883932, "y": 8.412025495280586}, {"x": 1.2963213501638993, "y": 8.820618861500712}, {"x": 0.7174304941346203, "y": 6.939978849632606}, {"x": 0.5156769049289194, "y": 6.2845429095992875}, {"x": 0.3475769349077156, "y": 5.738437324542827}, {"x": 0.14613332890684672, "y": 5.084008425494769}, {"x": 0.8452637147802509, "y": 7.355270034643096}, {"x": 1.595776876255243, "y": 9.793458626159062}, {"x": 1.82347707012953, "y": 10.5331871792189}, {"x": 1.409272492479724, "y": 9.187562708363972}, {"x": 0.9322760683137878, "y": 7.637946659913036}]}}, {"mode": "vega-lite"});
</script>
</div>

</div>

</div>
</div>

</div>
</div>
 

