{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "> Summary: Recurrent Neural Networks, RNN, LSTM, Long Short-term Memory, seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, TimeDistributed, Dense, RepeatVector\n",
    "\n",
    "#export\n",
    "def generate_data(training_size=10):\n",
    "    X = []\n",
    "    y = []\n",
    "    duplicates = set()\n",
    "    p_bar = tqdm(total=training_size)\n",
    "    while len(X) < training_size:\n",
    "        a = int(''.join(np.random.choice(list('0123456789')) for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "        b = int(''.join(np.random.choice(list('0123456789')) for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "        pair = tuple(sorted((a, b)))\n",
    "        if pair in duplicates:\n",
    "            continue\n",
    "        duplicates.add(pair)\n",
    "        pair_str = '{}+{}'.format(a,b)\n",
    "        pair_str = ' ' * (MAXLEN - len(pair_str)) + pair_str\n",
    "        ans = str(a + b)\n",
    "        ans = ' ' * ((DIGITS + 1) - len(ans)) + ans\n",
    "        X.append(pair_str)\n",
    "        y.append(ans)\n",
    "        p_bar.update(1)\n",
    "    return X,y\n",
    "\n",
    "#export\n",
    "def encode(questions, answers, alphabet):\n",
    "    char_to_index = dict((c, i) for i, c in enumerate(alphabet))\n",
    "    x = np.zeros((len(questions), MAXLEN, len(alphabet)))\n",
    "    y = np.zeros((len(questions), DIGITS + 1, len(alphabet)))\n",
    "    for q_counter, pair in enumerate(questions):\n",
    "        encoded_pair = np.zeros((MAXLEN, len(alphabet)))\n",
    "        for i, c in enumerate(pair):\n",
    "            encoded_pair[i, char_to_index[c]] = 1\n",
    "        x[q_counter] = encoded_pair\n",
    "    for a_counter, ans in enumerate(answers):\n",
    "        encoded_ans = np.zeros((DIGITS + 1, len(alphabet)))\n",
    "        for i, c in enumerate(ans):\n",
    "            encoded_ans[i, char_to_index[c]] = 1\n",
    "        y[a_counter] = encoded_ans\n",
    "    return x, y\n",
    "        \n",
    "\n",
    "    \n",
    "#export\n",
    "def decode(seq, alphabet, calc_argmax=True):\n",
    "    index_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "    if calc_argmax:\n",
    "        seq = np.argmax(seq, axis=-1)\n",
    "    return ''.join(index_to_char[c] for c in seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's generate some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 11661.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data... done!\n",
      "Size of Training set:  1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DIGITS = 3\n",
    "MAXLEN = DIGITS + DIGITS + 1\n",
    "n_training_examples = 1000\n",
    "print('Generating data...', end=' ')\n",
    "pairs,ans = generate_data(n_training_examples)\n",
    "print('done!')\n",
    "print('Size of Training set: ' , len(pairs))\n",
    "alphabet = list('0123456789+ ')\n",
    "x,y = encode(pairs, ans, alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data\n",
    "We split the data into training and testting sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape =  (900, 7, 12)\n",
      "y_train shape =  (900, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "print('x_train shape = ' , x_train.shape)\n",
    "print('y_train shape = ', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model\n",
    "Now it's time to build an RNN with LSTM cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 4, 12)             1548      \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(MAXLEN, len(alphabet))))\n",
    "model.add(RepeatVector(DIGITS + 1))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(len(alphabet), activation='softmax')))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "After we builded and compiled the model, we must train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1\n",
      "Train on 900 samples, validate on 100 samples\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 1.5905 - accuracy: 0.3958 - val_loss: 1.6040 - val_accuracy: 0.3925\n",
      "Q:   5+340   Actual:  345 \u001b[91m  ☒\u001b[0m Guessed:  155\n",
      "Q:   5+721   Actual:  726 \u001b[91m  ☒\u001b[0m Guessed:  155\n",
      "Q:    27+7   Actual:   34 \u001b[91m  ☒\u001b[0m Guessed:   22\n",
      "Q:  91+665   Actual:  756 \u001b[91m  ☒\u001b[0m Guessed:  155\n",
      "Q:   388+9   Actual:  397 \u001b[91m  ☒\u001b[0m Guessed:  155\n",
      "Q:  941+23   Actual:  964 \u001b[91m  ☒\u001b[0m Guessed:  155\n",
      "Q:   17+67   Actual:   84 \u001b[91m  ☒\u001b[0m Guessed:   55\n",
      "Q:  91+665   Actual:  756 \u001b[91m  ☒\u001b[0m Guessed:  155\n",
      "Q: 204+890   Actual: 1094 \u001b[91m  ☒\u001b[0m Guessed:  555\n",
      "Q:     5+9   Actual:   14 \u001b[91m  ☒\u001b[0m Guessed:    2\n",
      "Iteration  2\n",
      "Train on 900 samples, validate on 100 samples\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 1.5800 - accuracy: 0.4006 - val_loss: 1.6091 - val_accuracy: 0.4025\n",
      "Q:   7+471   Actual:  478 \u001b[91m  ☒\u001b[0m Guessed:  449\n",
      "Q:  672+52   Actual:  724 \u001b[91m  ☒\u001b[0m Guessed:  499\n",
      "Q:    51+1   Actual:   52 \u001b[91m  ☒\u001b[0m Guessed:   34\n",
      "Q: 757+459   Actual: 1216 \u001b[91m  ☒\u001b[0m Guessed: 1444\n",
      "Q:    51+1   Actual:   52 \u001b[91m  ☒\u001b[0m Guessed:   34\n",
      "Q:   5+721   Actual:  726 \u001b[91m  ☒\u001b[0m Guessed:  149\n",
      "Q:     9+2   Actual:   11 \u001b[91m  ☒\u001b[0m Guessed:   34\n",
      "Q:     5+9   Actual:   14 \u001b[92m  ☑\u001b[0m Guessed:   14\n",
      "Q:  547+73   Actual:  620 \u001b[91m  ☒\u001b[0m Guessed:  499\n",
      "Q:     4+4   Actual:    8 \u001b[91m  ☒\u001b[0m Guessed:   14\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print('Iteration ', epoch)\n",
    "    model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=1, validation_data=(x_test, y_test), verbose=1)\n",
    "    # Select 10 samples from test set and visualize errors\n",
    "    for i in range(10):\n",
    "        index = np.random.randint(0, len(x_test))\n",
    "        q = x_test[np.array([index])]\n",
    "        ans = y_test[np.array([index])]\n",
    "        preds = np.argmax(model.predict(q),axis=-1)\n",
    "        question = decode(q[0],alphabet)\n",
    "        actual = decode(ans[0],alphabet)\n",
    "        guessed = decode(preds[0], alphabet, calc_argmax=False)\n",
    "        print('Q:', question, end=' ')\n",
    "        print('  Actual:', actual, end=' ')\n",
    "        if actual == guessed:\n",
    "            print(colors.ok + '  ☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '  ☒' + colors.close, end=' ')\n",
    "        print('Guessed:', guessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
